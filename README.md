# Optimizing an ML Pipeline in Azure

## Overview
This project is part of the Udacity Azure ML Nanodegree.
In this project, we build and optimize an Azure ML pipeline using the Python SDK and a provided Scikit-learn model.
This model is then compared to an Azure AutoML run.

## Useful Resources
- [ScriptRunConfig Class](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.scriptrunconfig?view=azure-ml-py)
- [Configure and submit training runs](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-set-up-training-targets)
- [HyperDriveConfig Class](https://docs.microsoft.com/en-us/python/api/azureml-train-core/azureml.train.hyperdrive.hyperdriveconfig?view=azure-ml-py)
- [How to tune hyperparamters](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-tune-hyperparameters)


## Summary
This dataset contains data from individuals who respond to a bank marketing some kind of product/subscription/service. 
We seek to predict, wether the client subscribes to the offered service.

The best performing model vas a VotingEnsemble model, which performs with an accuracy of 0.917.

## Scikit-learn Pipeline
### Processing data
Data processing steps:
1. Converting CSV data to pandas dataframe and dropping those instances that have NaN values
2. Converting *job*, *education* and *contact* attribute to one-hot-encoded data instead of categorical
3. Converting *marital*, *default*, *housing*, *loan*, *y* and *poutcome* to binary categories
4. Split data into labels (*y* column) and features.
5. Split datasets into training and test sets.

### Hyperparameter tuning

The two hyperparameters to be tuned:
- **max_iter**: Maximum number of iterations for the model to be trained on. For this parameter I specified 6 discrete values (25, 50, 100, 150, 200, 250)
- **C**: Regularization parameter for the regression. I set this as a uniform distribution between 0.001 and 1.

Chosen hyperparameters for the best model:
- Maximum number of iterations: 100
- Regularization strength: 0.535

#### Sampling: RandomParameterSampling
Random Parameter Sampling chooses parameters from a prespecified set of discrete parameters or a continuous limited set. This sampler chooses parameters randomly, this way we do not have to check each parameter combination. This is a time-efficient way of sampling parameters.


#### Stopping policy: Bandit
The bandit policy terminates runs where the primary metric is not within the specified slack factor (0.1) compared to the best performing model. Setting this policy ensures that models performing 10% worse than already trained models, will not be trained full, therefore we can spare time.

### Classification algorithm

The classification algorithm is a Logistic Regression, which classifies data by first estimating the probability of the customer subscribing, and then applying an activation function (sigmoid) on the probabilities, thus creating binary outputs.


## AutoML
**In 1-2 sentences, describe the model and hyperparameters generated by AutoML.**
The best model trained by AutoML was a VotingEnsemble (XGBoosted algorithm). XGBoost optimizes accuracy by combining the output of multiple, weaker tree models.

Hyperparameter:
- **colsample_bytree**: 0.9. This parameter defines the percentage of columns that will be used for building each weak model.
- **eta**: 0.1. This is the same as learning rate.
- **gamma**: 0. Specifies the minimum loss reduction for splitting a node. (No minimum loss, can result in large node number trees)
- **max_depth**: 6. Maximum depth of a tree
- **max_leaves**: 3. Maximum number of nodes.
- **n_estimators**: 25. Number of estimators
- **objective**: 'reg:logistic'. Loss function to be minimized - in this case Logistic regression (alpha (L1 regularization): 0, lambda (L2 regularization): 0.73)
- **subsample**: 0.5. Percentage of training instances to be used for each tree.
- **tree_method**: 'auto'. Automatic choice of the fastest way to build the trees.

## Pipeline comparison
**Compare the two models and their performance. What are the differences in accuracy? In architecture? If there was a difference, why do you think there was one?**

|   Model   |   Accuracy   |
|---|---|
|  LogisticRegression  |  0.909  |
|  VotingEnsemble  |  0.917  |

The first algorithm is a regression, the other is a combination of tree models. Similar performance can be due to the objective of the XGBoost(Logistic regression).
We can see that there's no significant difference between the two models (8%).

## Future work

For the logistic regression, the provided range for the regularization strength was too small. Since smaller numbers mean stronger regularization, the possibility for weaker regularization could have resulted in better accuracy.

